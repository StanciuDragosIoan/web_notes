<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link
      href="https://fonts.googleapis.com/css2?family=Domine:wght@400;700&family=Open+Sans:ital,wght@0,400;0,600;0,700;1,400;1,600;1,700&family=Roboto&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="../../assets/css/main.css" type="text/css" />
    <title>ChatGPT</title>
  </head>

  <body>
    <h1 class="header"></h1>
    <p class="text">
      <span class="snippet">ChatGTP</span> is a web application which we can use
      in a browser to ask it any kind of questions and get all kinds of
      responses to these questions.
      <br />
      It can vastly boost productivity and it may replace certain jobs.
      <br />
      However, people who know how to use it well, will probably benefit from
      and in order to understand its capabilities and features we should have a
      'behind the scenes' look
    </p>
    <p class="text title">What is <span class="snippet">ChatGTP</span> ?</p>
    <p class="text">
      It is a <span class="snippet">web-based AI</span> chat bot and we can chat
      on it about any topic. It can draft emails, summarize articles, write
      code, etc..
    </p>
    <p class="text title">
      Alternatives to <span class="snippet">ChatGPT</span>
    </p>
    <p class="text">
      Alternative bots would be <span class="snippet">Google Bard</span> or
      <span class="snippet">Bing Chat</span>.
    </p>
    <p class="text title">
      <span class="snippet">ChatGPT</span> under the hood
    </p>
    <p class="text">
      <span class="snippet">ChatGPT</span> is based on the
      <span class="snippet">GPT model</span>. In this context
      <span class="snippet">GPT</span> stands for 'Generative Pretrained
      Transformer'.
    </p>
    <p class="text">
      The <span class="snippet">GPT</span> model is an AI model, created by the
      <span class="snippet">OpenAI</span> company. This model is what
      <span class="snippet">ChatGPT</span> uses under the hood.
    </p>
    <p class="text">
      So <span class="snippet">ChatGPT</span> is the web app with which we
      interact in the browser to ask it questions and get back answers and the
      <span class="snippet">GPT</span> model is the underlying program, used by
      the <span class="snippet">ChatGPT</span> app to produce and generate
      responses. The <span class="snippet">GPT</span> model exposes some
      <span class="snippet">GPT APIs</span> which
      <span class="snippet">ChatGPT</span> leverages, but which we as developers
      can also use to build our own programs that incorporate and implement
      <span class="snippet">GPT AI</span> models.
    </p>
    <p class="text title">GPT Model</p>
    <p class="text">
      The <span class="snippet">GPT AI</span> model is a
      <span class="snippet">large language model</span>. A 'language model' is a
      type of <span class="snippet">AI Algorithm</span> that uses
      <span class="snippet">Deep Learning</span> techniques and massive data
      sets to understand, summarise, generate and predict content.
    </p>
    <p class="text">
      <span class="snippet">Large Language Models</span> are machine learning
      models that perform natural language processing tasks. They are built and
      optimised to understand and process text, that is understood by humans.
      They are 'trained to calculate probabilities' to suggest words based on
      previous words. So they can complete sentences of words.
    </p>
    <p class="text">
      In a nut-shell these
      <span class="snippet">large language models</span> take some input in the
      form of text and produce some output to complete a sequence of words. This
      could also be a sequence of numbers, or just any sequence such as when we
      ask a question and the continuation to that sequence is an answer and so
      on.
    </p>
    <p class="text title">
      <span class="snippet">Large Language Models</span> and
      <span class="snippet">Machine Learning</span>
    </p>
    <p class="text">
      <span class="snippet">Large Language Models</span> are
      <span class="snippet">neural networks</span>. These
      <span class="snippet">neural networks</span> are computer programs that
      connect a vast amount of input and calculation notes, organized across
      multiple layers to then produce an output.
    </p>
    <p class="text">
      There are different types of
      <span class="snippet">neural networks</span> for different purposes, for
      instance we could train an <span class="snippet">AI model</span> to work
      with images.
    </p>
    <p class="text">
      The neural networks that work with text are of the
      <span class="snippet">Transformer</span> type and they are also called
      Transformers or <span class="snippet">Transformer Neural Network</span>.
    </p>
    <p class="text">
      The idea behind these transformers is that we train the network such that
      for given inputs, for given text, it produces outputs, words that produce
      logically sound sequences of words. This is done through an
      <span class="snippet">iterative training process</span>. In this process
      words are fed into the network and the outputs are then compared to the
      input words to see if the sequence overall makes sense.
    </p>
    <p class="text">
      For instance for the <span class="snippet">GPT 3.5</span> model used by
      <span class="snippet">ChatGPT</span> more than
      <span class="snippet">170 billion</span> parameters were used and
      organized across <span class="snippet">96 layers</span>.
    </p>
    <p class="text">
      So these <span class="snippet">GPT models</span> are quite complex, and
      they complete sequences of words and predict words based on billions of
      parameters.
    </p>

    <p class="text title">
      The <span class="snippet">ChatGPT</span> training data and
      <span class="snippet">Tokens</span>
    </p>
    <p class="text">
      The data used to train the <span class="snippet">GPT</span> model was the
      entire publically available text data from the internet, not only in
      English but in other languages as well. Therefore
      <span class="snippet">ChatGPT</span> 'knows' a lot of patterns and
      received a lot of input data.
    </p>
    <p class="text">
      After this data was curated (e.g. some parts that could produce malicious
      or dangerous content were removed), it was fed into the AI model to train
      it. The way in which it was fed into the model was through
      <span class="snippet">Tokens</span>.
    </p>
    <p class="text">
      A <span class="snippet">token</span> is not necessarily an entire word, it
      can be part of a word. Roughly 75 words can be broken up into about 100
      tokens.
    </p>
    <p class="text">
      These <span class="snippet">tokens</span> and their
      <span class="snippet">IDs</span> are being used as input for the neural
      networks to train the AI model.
    </p>
    <p class="text title">Predicting words</p>
    <p class="text">
      So these large and fancy language models are ultimately all about
      predicting words, completing sentences, predicting the next most fit word
      in an incomplete sentence, etc...
    </p>
    <p class="text">
      Words that get output by <span class="snippet">ChatGPT</span> are all
      based on the words in front of it. So
      <span class="snippet">ChatGPT</span> continuously checks these words, and
      the words it output thus far, and then generates possible next words. It
      assigns probabilities to those words and picks the ones that have the
      highest probability.
    </p>
    <p class="text">
      These predicitons are not just 'matematichal',
      <span class="snippet">ChatGPT</span> can 'reason' about words and ideas it
      'knows' (so stuff it has already processed). So
      <span class="snippet">GPT</span> models are able to understand complex
      relations. They can predict words based on relations across multiple
      sentences or more complex word combinations.
    </p>
    <p class="text">
      That is why <span class="snippet">ChatGPT</span> can seem 'magical' as if
      it really understand what we are asking it. Yet it is only predicting
      words based on the user input and on the available context (previous
      inputs/outputs it generated).But because of the complexity of these GPT
      models, it's able to predict these words really well and it's able to
      produce complex output and complex text like this one here.
    </p>
    <p class="text title">Model fine-tuning</p>
    <p class="text">
      <span class="snippet">ChatGPT</span> is based on the
      <span class="snippet">GPT</span> models, which are large language models
      trained with billions of parameters and dozens of layers.
    </p>
    <p class="text">
      Once the model had been trained, it was also 'fine tuned' so
      <span class="snippet">ChatGPT</span> has a
      <span class="snippet">moderation API</span> (owned by
      <span class="snippet">OpenAI</span>) which makes sure that certain
      questions cannot be asked.So through that moderation program you could
      say. Simply to make sure that both the input and the output are free from
      dangerous or malicious text, so that you, for example, can't ask how to
      build a bomb.
    </p>
    <p class="text title"><span class="snippet">ChatGPT</span> limitations</p>
    <p class="text">
      When working with <span class="snippet">ChatGPT</span>, certain kinds of
      inputs simply aren't allowed because of this moderation program, which in
      the end scans all inputs and outputs before allowing them.
    </p>
    <p class="text">
      There are also other limitations to
      <span class="snippet">ChatGPT</span> for instance limited training data.
    </p>
    <p class="text">
      As mentioned, a huge amount of data was used for training the model, but
      since training such a complex model does indeed take very long, it
      actually takes multiple months to train such a model, training data has to
      be cut off at a certain point of time. For example,
      <span class="snippet">GPT 3.5</span> only has data until September 2021.
      So if you are asking questions that would require knowledge past September
      21, ChatGPT would not be able to help you.
    </p>
    <p class="text">
      Another thing worth mentioning is that even though these responses which
      you get from <span class="snippet">ChatGPT</span> can seem very logical
      and magical, it's about patterns, not logic.
    </p>
    <p class="text">
      <span class="snippet">ChatGPT</span> predicts words. It assigns
      probabilities and picks words based on probabilities. It doesn't really
      understand us, even though it often seems like it does.
    </p>
    <p class="text">
      <span class="snippet">ChatGPT</span> in its raw form can only handle an
      output text. It can't search the internet and it can't execute code, for
      example.
    </p>
    <p class="text title">Limited Context and Token Limits</p>
    <p class="text">
      Since the <span class="snippet">GPT</span> models have a limit to how much
      stuff they can process at once,there is a
      <span class="snippet">token limit</span> to the input we send to
      <span class="snippet">ChatGPT</span>.
    </p>
    <p class="text">
      There is also a limit to the entire chat history.
      <span class="snippet">ChatGPT</span> keeps track of the context discussed
      with you through the chat history. This allows you to ask
      <span class="snippet">ChatGPT</span> about something that might have been
      part of an earlier chat message. But therefore, of course, it's always the
      entire chat that has to be handled by chat
      <span class="snippet">GPT</span> as an input and therefore it's the tokens
      of that entire chat that are taken into account by chat GPT and that count
      towards that token limit.
    </p>
    <p class="text">
      For instance <span class="snippet">ChatGPT</span> does not allow super
      long prompts. If you, for example, want to use
      <span class="snippet">ChatGPT</span> to summarize a very long document and
      you paste in the entire document combined with your prompt, your question,
      <span class="snippet">ChatGPT</span> might not accept this. Besides that,
      <span class="snippet">ChatGPT</span> also simply starts to forget certain
      things as your chat history grows. If you go beyond that token limit,
    </p>
    <p class="text title">Differences between GPT 3.5 and GPT 4</p>
    <p class="text">
      There are 3 categories of differences: speed, reasoning and conciseness.
    </p>
    <p class="text">
      When it comes to speed, <span class="snippet">GPT 3.5</span> is much
      faster than <span class="snippet">GPT 4.</span> The reasoning of
      <span class="snippet">ChatGPT 4</span> is way more advanced than the
      reasoning of 3.5. As <span class="snippet">ChatGPT 4</span>
      was trained with way more data and is also able to process a lot more
      data, it simply can calculate the probabilities for the next character,
      word or sentence based on a bigger database. And therefore the information
      <span class="snippet">ChatGPT 4</span> provides or the output it provides
      is more elaborated and more logical. As for conciseness
      <span class="snippet">ChatGPT 4</span> is also way stronger than
      <span class="snippet">ChatGPT 3.5</span>. Conciseness here simply can be
      described as efficiency. ChatGPT tries to provide the output with all
      required information with as less words and as less tokens as possible.
    </p>
    <p class="text title">Prompts</p>
    <p class="text">
      These are questions we ask to <span class="snippet">ChatGPT</span> and as
      <span class="snippet">ChatGPT</span> is context aware, the prompts should
      be as targeted and as specific as possible. We can also edit the prompts
      and regenerate responses (for more accuracy).
    </p>
    <p class="text title">Hallucinations (wrong answers)</p>
    <p class="text">
      <span class="snippet">ChatGPT</span> can answer a lot of questions but
      sometimes it can create incorrect and non-cntext-related output that still
      sounds perfectly plausible. (e.g. if I give him a link with a blog article
      from 2022, and ask it to summarize, it will 'pretend it knows' and do it
      although its training data is only up to 2021).
    </p>
    <p class="text title">Continuing output generation</p>
    <p class="text">
      Sometimes the output generated by <span class="snippet">ChatGPT</span> is
      longer than the token limit, so it will jsut stop. For instance if we ask
      him to summarize a super long text, it will stop midway. However, we can
      'continue' the output generation once
      <span class="snippet">ChatGPT</span> stops by simply typing in 'continue'.
    </p>
    <p class="text title">ChatGPT plugins</p>
    <p class="text">
      Plug-ins are tools that can be used in connection with ChatGPT with the
      goal to enhance ChatGPT's capabilities. One core application area for such
      plug-ins is code execution. So with plugins, we would be able to write and
      execute code directly in the browser.
    </p>
    <p class="text">
      Another core thing ChatGPT doesn't have at the moment by default is
      internet access. Internet access is also one of the core areas tackled by
      plug-ins because with internet access, we could retrieve latest data well,
      by connecting ChatGPT to the internet.
    </p>
    <p class="text">However, currently plugins are not publically available.</p>
    <p class="text">
      Let's say you wanna plan a city trip with the help of ChatGPT, therefore
      you would get started to enable required plug-ins first. So plug-ins that
      are required for a city trip could be a plug-in to get access to a website
      that allows you to book flights and hotels. And if you're looking for
      restaurants, you could also activate the plug-in that allows you to book a
      table at a restaurant. The typical way to plan the trip now could be to
      select a destination first. So you could, for example, let ChatGPT give
      you a list of great travel destinations, and then you select one.
      Afterwards, you let ChatGPT book the flight and the hotel. Once you are at
      the destination, you could also use ChatGPT and to plug-in to find a
      restaurant and to book a table at the restaurant of your choice.
    </p>
    <p class="text title">
      Alternatives to ChatGPT (Microsoft Bing and Google Bard)
    </p>
    <p class="text center">Microsoft Bing</p>
    <p class="text">
      Microsoft Bing is a chatbot from Microsoft. We can use it by signing in
      with a microsoft account. It uses web search results and combines them
      with AI generated responses to our prompts.
    </p>
    <p class="text">
      Under the hood, Microsoft Bing uses GPT models (similarly to ChatGPT).
    </p>
    <p class="text">
      Microsoft Bing uses web searches for its responses, it provides responses
      and embeds links for the sources used in these responses.
    </p>
    <p class="text">
      Bing has a creative, balanced and a precise mode for the conversations.
    </p>
    <p class="text title">Google Bard</p>
    <p class="text">The google's AI chatbot is Google bard.</p>
    <p class="text header">Prompt Engineering</p>
    <p class="text">
      Propmpt engineering is important because it will help us write good
      propmpts (and get good responses). Good propmpts should have specific
      context.
    </p>
    <p class="text">
      A good propmpts has 2 main elements: the goal + some additional
      context/info so that ChatGPT produces a better result. For many prompts we
      should assign a role to ChatGPT (e.g. if I want a tweet from ChatGPT I
      will tell him 'you are an experienced Twitter user, known for posting
      highly engaging tweets that lead users to like and retweet posted tweets.
      Write a twwt about hiking').
    </p>
    <p class="text">
      We can alos add extra constraints or extra information to the prompt such
      as 'The tweet should have 2 emoji at most, and the target audience should
      be nature enthusiasts.'
    </p>

    <p class="text">#showInPresentation</p>
    <p class="text">
      The best way to write a good prompt is to add more context, so to
      'continue' the conversation si that ChatGPT can better tweak the response
      more.
    </p>
    <p class="text">#showInPresentation</p>
    <p class="text">
      We can specify the output format as: Text, JSON, XML, etc..
    </p>
  </body>
</html>

<!-- start from video 43 

  <p class="text">#showInPresentation</p>

  check all notes and add the above p
-->

<!-- /*

  Revenue

  Net, absolute

  Discount, absolute

  Gross, absolute

  Cashflow quarterly (there is an 'outputs-cashflow' entry but I am not sure if we should have the exact value as in design or not)

  Administrations total

  Packs total

  Active patients

  Selected timeframe

  Patients annual

*/ -->
